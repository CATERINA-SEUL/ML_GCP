#### 1. Which of the following activation functions are used for nonlinearity?

A : All of the above
    - Sigmoid
    - Hyperbolic tangent
    - Tanh

#### 2. A single unit for a non-input neuron has ____________________ a/an

A : All of the above
    - Weighted Sum
    - Activation function
    - Output of the activation function

#### 3. If we wanted our outputs to be in the form of probabilities, which activation function should I choose in the final layer?

A : Sigmoid

#### 4. Which activation functions are needed to get the complex chain functions that allow neural networks to learn data distributions.

A : Nonlinear activation functions

#### 5. Which activation function has a range between zero and Infinity?

A : ReLU