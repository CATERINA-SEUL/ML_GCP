#### 1. What is L2 Regularization?

A : Added to sum of the squared parameter weights terms to the last function

#### 2. What is L1 Regularization?

A : Adds the sum of the absolute value the parameter weights to the last function

#### 3. What are the benefits of sparse model?

A : All of the above

    Reduction in storage and memory
    Increased training speed
    Increase prediction speed

#### 4. What are the differences between L1 regularization and L2 regularization?

A : L1 regularization tends to shrink coefficients to zero whereas L2 regularization tends to shrink coefficients evenly.

#### 5. Why is it recommended that a high-dimensional sparse vector weight drop to exactly 0?

A : All of the above

    This essentially removes the corresponding feature from the model
    Zeroing out features will save RAM
    May reduce noise in the model